{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "from pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.95.41:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>odl</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=odl>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conf = pyspark.SparkConf().setAppName('odl').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sqlc = pyspark.sql.SQLContext(sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::846033058400:role/service-role/AmazonSageMaker-ExecutionRole-20190115T085426'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket='odl-spark19spds6003-001'\n",
    "data_key = 'nk4xf/heart.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "pddf = pd.read_csv(data_location)\n",
    "pddf = pddf.dropna()\n",
    "pddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlc.createDataFrame(pddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'path file:/home/ec2-user/SageMaker/nk4xf/nk4xf-parquet already exists.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o38.parquet.\n: org.apache.spark.sql.AnalysisException: path file:/home/ec2-user/SageMaker/nk4xf/nk4xf-parquet already exists.;\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:106)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:435)\n\tat org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:471)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:50)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:609)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:233)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:217)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:508)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5176392e153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparquetPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./nk4xf-parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# writing to local parquet store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquetPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'path file:/home/ec2-user/SageMaker/nk4xf/nk4xf-parquet already exists.;'"
     ]
    }
   ],
   "source": [
    "parquetPath = './nk4xf-parquet'\n",
    "# writing to local parquet store\n",
    "df.write.parquet(parquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing from parquet to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files from local parquet store\n",
    "files = [f for f in listdir(parquetPath) if isfile(join(parquetPath, f))]\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "for f in files:\n",
    "    s3.Bucket(bucket).upload_file(parquetPath+'/'+f, \"nk4xf/pqt/\"+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from parquet into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlc.read.parquet(parquetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=63, sex=1, cp=3, trestbps=145, chol=233, fbs=1, restecg=0, thalach=150, exang=0, oldpeak=2.3, slope=0, ca=0, thal=1, target=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27935090656128797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr('age','trestbps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low correlation observed between age and resting blood pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2136779565595619"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr('age','chol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low correlation observed between age and chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12317420653239047"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr('trestbps','chol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low correlation observed between trestbps and chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"age\",\"sex\",\"trestbps\",\"chol\",\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7956073\n",
    "(testDF, trainingDF) = df.randomSplit((0.20, 0.80), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set N = 247, test set N = 56\n"
     ]
    }
   ],
   "source": [
    "print ('training set N = {}, test set N = {}'.format(trainingDF.count(),testDF.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=29, sex=1, trestbps=130, chol=204, target=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using VectorAssembler to vectorize multiple features\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# defining custom function to convert input into vector\n",
    "sqlc.registerFunction(\"oneElementVec\", lambda d: Vectors.dense([d]), returnType=VectorUDT())\n",
    "\n",
    "featureCols = ['age','sex','trestbps','chol']\n",
    "\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=featureCols,outputCol=\"features\")\n",
    "trainingDF = assembler.transform(trainingDF)\n",
    "\n",
    "#### Ref - https://stackoverflow.com/questions/32556178/create-labeledpoints-from-spark-dataframe-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=29, sex=1, trestbps=130, chol=204, target=1, features=DenseVector([29.0, 1.0, 130.0, 204.0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.mllib.regression import LabeledPoint\n",
    "#trainingDF = LabeledPoint(trainingDF.target, trainingDF.features)\n",
    "\n",
    "trainingDF = trainingDF.withColumnRenamed(\"target\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF = trainingDF.select('label','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingDF = trainingDF.rdd.map(lambda x: LabeledPoint(x['label'],x['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingDF.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "logit_model = LogisticRegression().fit(trainingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing test data\n",
    "\n",
    "testDF = assembler.transform(testDF)\n",
    "testDF = testDF.withColumnRenamed(\"target\", \"label\")\n",
    "testDF = testDF.select('label','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, features=DenseVector([41.0, 1.0, 120.0, 157.0]), rawPrediction=DenseVector([-0.9697, 0.9697]), probability=DenseVector([0.2749, 0.7251]), prediction=1.0), Row(label=1, features=DenseVector([44.0, 1.0, 120.0, 226.0]), rawPrediction=DenseVector([-0.5872, 0.5872]), probability=DenseVector([0.3573, 0.6427]), prediction=1.0), Row(label=1, features=DenseVector([41.0, 1.0, 135.0, 203.0]), rawPrediction=DenseVector([-0.6927, 0.6927]), probability=DenseVector([0.3334, 0.6666]), prediction=1.0), Row(label=1, features=DenseVector([38.0, 1.0, 138.0, 175.0]), rawPrediction=DenseVector([-0.9384, 0.9384]), probability=DenseVector([0.2812, 0.7188]), prediction=1.0), Row(label=1, features=DenseVector([42.0, 1.0, 140.0, 226.0]), rawPrediction=DenseVector([-0.5122, 0.5122]), probability=DenseVector([0.3747, 0.6253]), prediction=1.0)]\n"
     ]
    }
   ],
   "source": [
    "predictionsAndLabelsDF = logit_model.transform(testDF)\n",
    "\n",
    "print(predictionsAndLabelsDF.orderBy(predictionsAndLabelsDF.label.desc()).take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ref - http://spark.apache.org/docs/latest/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = logit_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(summary.roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocDF = summary.roc.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FPR       TPR\n",
       "0  0.0  0.000000\n",
       "1  0.0  0.014815\n",
       "2  0.0  0.029630\n",
       "3  0.0  0.044444\n",
       "4  0.0  0.059259"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff9d1b1a828>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting ROC curve\n",
    "\n",
    "rocDF.plot(x='FPR',y='TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397817460317462"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.LogisticRegressionModel"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
